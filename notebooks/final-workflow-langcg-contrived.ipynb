{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1387de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrived example using json as our questionnaire repository, with a RAG based questionnaire discover system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2b767-49fe-4d9d-89d3-25cc5545a300",
   "metadata": {},
   "source": [
    "# AI-Powered Clinical Documentation Assistant\n",
    "\n",
    "# Background\n",
    "\n",
    "Healthcare professionals face a significant burden from medical documentation. This project focuses on leveraging generative AI to alleviate this burden by automatically extracting structured information from physician-patient audio conversations and using it to pre-fill administrative forms by generating data points that can be electronically stored in EMRs, and EHRS.\n",
    "\n",
    "This tool outputs data in a FHIR compatible format which ensures seamless integration with existing healthcare systems through a standardized, interoperable format. This structured approach unlocks the data's potential for reusability in various clinical workflows, analytics, and future healthcare applications beyond just form filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b16edec1-7f10-4386-a87b-1ff60397b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n",
    "!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\" \"langchain==0.3.23\" \"langgraph==0.3.29\" \"json-repair==0.41.1\" \"google-api-core==2.24.2\" \"langchain-google-genai==2.1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17849f-1c4b-4570-8642-8eedbd36e43d",
   "metadata": {},
   "source": [
    "**Set up your API key**\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61d848d2-0ffc-478d-a4ee-fd02e8636e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd7f71ec-1170-42a2-85ec-5e03ea497f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_API_KEY=\"AIzaSyDAZjElfeaJqItRsB21v3p4ETShat1PzmI\"\n",
    "\n",
    "# print(dict(os.environ))\n",
    "\n",
    "# os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323ff8b-d9fd-4917-8a37-92f6305d14f1",
   "metadata": {},
   "source": [
    "**Prepare the data store and embeddings**\n",
    "\n",
    "Discover the questionnaire metadata that we will use to create an embedding database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5f52747-cebb-40ee-8e1d-a33c52a638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "# HAPI_FHIR_BASE_URL = \"https://hapi.fhir.org/baseR4\"\n",
    "# HAPI_FHIR_BASE_URL = \"http://localhost:8081/fhir\"\n",
    "# QUESTIONNAIRE_ENDPOINT = f\"{HAPI_FHIR_BASE_URL}/Questionnaire\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa050ee6-6a3c-411c-b352-da10c5a98e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('No description', {'id': '47004539', 'title': 'AAA New Form'}), ('No description', {'id': '47004537', 'title': 'ee New Form'}), ('No description', {'id': '47004533', 'title': 'New Form'}), ('No description', {'id': 'adc-extraction-test-1', 'title': 'Extraction test - Karnofsky/Lansky Score'}), ('No description', {'id': '47002099', 'title': 'Demographic Survey', 'name': 'Demographic Survey'}), ('No description', {'id': '46994390', 'title': 'Extraction test - Karnofsky/Lansky Score'}), ('A questionnaire to collect basic health history information.', {'id': 'health-history-questionnaire-2021-06', 'title': 'Health History Questionnaire (June 2021)'}), ('Questionnaire for routine collection of vital signs and physical observations.', {'id': 'routine-obs', 'title': 'Routine Observation Questionnaire', 'name': 'RoutineObservation'}), ('A standardized questionnaire to assess depression severity over the last 2 weeks.', {'id': 'phq9', 'title': 'Patient Health Questionnaire-9 (PHQ-9)', 'name': 'PHQ9'}), ('No description', {'id': '46934304', 'name': 'LifelinesQuestionnaire'})], ['47004539', '47004537', '47004533', 'adc-extraction-test-1', '47002099', '46994390', 'health-history-questionnaire-2021-06', 'routine-obs', 'phq9', '46934304'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "_quest_docs = None\n",
    "\n",
    "\n",
    "def read_questionnaires_from_store():\n",
    "    global _quest_docs\n",
    "    if _quest_docs is None:\n",
    "        with open(\"./quest.db.json\", \"r\") as file:\n",
    "            _quest_docs = json.loads(file.read())\n",
    "    return _quest_docs\n",
    "\n",
    "\n",
    "def get_quest_docs_meta():\n",
    "    quest_docs = read_questionnaires_from_store()\n",
    "    doc_with_metad = []\n",
    "    doc_ids = []\n",
    "    for doc in quest_docs:\n",
    "        doc_id = doc.get(\"id\")\n",
    "        doc_meta = {\n",
    "            k: v\n",
    "            for k, v in {\n",
    "                \"id\": doc_id,\n",
    "                \"title\": doc.get(\"title\"),\n",
    "                \"name\": doc.get(\"name\"),\n",
    "            }.items()\n",
    "            if v is not None\n",
    "        }\n",
    "        doc_desc = (\n",
    "            doc.get(\"description\") if doc.get(\"description\") else \"No description\"\n",
    "        )\n",
    "        doc_with_metad.append((doc_desc, doc_meta))\n",
    "        doc_ids.append(doc_id)\n",
    "    return doc_with_metad, doc_ids\n",
    "\n",
    "\n",
    "print(get_quest_docs_meta())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2631970-c89c-4e49-9a98-f1423ca6ac8c",
   "metadata": {},
   "source": [
    "## Creating the embedding database with ChromaDB\n",
    "\n",
    "We create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. \n",
    "\n",
    "The questionnaire metadata are the items that are in the database. They are inserted first, and later retrieved. Queries will be a description of the form to be filled derived from the prompt instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9e9279a-aa5f-4821-96d0-ac08fea942d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "from google.genai import types, Client\n",
    "\n",
    "gda_client = Client(api_key=GOOGLE_API_KEY)\n",
    "gda_client_model = \"gemini-2.0-flash\"\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        response = gda_client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=embedding_task,\n",
    "            ),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9532e-3916-4f60-a52c-364bdd0bcbd2",
   "metadata": {},
   "source": [
    "Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `GeminiEmbeddingFunction` and populate the database with the questionnaire metadata from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d84b8cfc-ee27-4017-a56c-65e64f798f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'id': '47004539', 'title': 'AAA New Form'}, {'id': '47004537', 'title': 'ee New Form'}, {'id': '47004533', 'title': 'New Form'}, {'id': 'adc-extraction-test-1', 'title': 'Extraction test - Karnofsky/Lansky Score'}, {'id': '47002099', 'title': 'Demographic Survey', 'name': 'Demographic Survey'}, {'id': '46994390', 'title': 'Extraction test - Karnofsky/Lansky Score'}, {'id': 'health-history-questionnaire-2021-06', 'title': 'Health History Questionnaire (June 2021)'}, {'id': 'routine-obs', 'title': 'Routine Observation Questionnaire', 'name': 'RoutineObservation'}, {'id': 'phq9', 'title': 'Patient Health Questionnaire-9 (PHQ-9)', 'name': 'PHQ9'}, {'id': '46934304', 'name': 'LifelinesQuestionnaire'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: 47004539\n",
      "Insert of existing embedding ID: 47004537\n",
      "Insert of existing embedding ID: 47004533\n",
      "Insert of existing embedding ID: adc-extraction-test-1\n",
      "Insert of existing embedding ID: 47002099\n",
      "Insert of existing embedding ID: 46994390\n",
      "Insert of existing embedding ID: health-history-questionnaire-2021-06\n",
      "Insert of existing embedding ID: routine-obs\n",
      "Insert of existing embedding ID: phq9\n",
      "Insert of existing embedding ID: 46934304\n",
      "Add of existing embedding ID: 47004539\n",
      "Add of existing embedding ID: 47004537\n",
      "Add of existing embedding ID: 47004533\n",
      "Add of existing embedding ID: adc-extraction-test-1\n",
      "Add of existing embedding ID: 47002099\n",
      "Add of existing embedding ID: 46994390\n",
      "Add of existing embedding ID: health-history-questionnaire-2021-06\n",
      "Add of existing embedding ID: routine-obs\n",
      "Add of existing embedding ID: phq9\n",
      "Add of existing embedding ID: 46934304\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"fhir-quest-semantic\"\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "def populate_vector_db():\n",
    "    embed_fn.document_mode = True\n",
    "    (desc_with_metad, doc_ids) = get_quest_docs_meta()\n",
    "    descriptions, meta = zip(*desc_with_metad)\n",
    "    print(meta)\n",
    "\n",
    "    db.add(documents=list(descriptions), ids=doc_ids, metadatas=list(meta))\n",
    "\n",
    "populate_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5598e8-acac-43cf-8713-1dae231217e3",
   "metadata": {},
   "source": [
    "Confirm that the data was inserted by looking at the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5000694e-9d36-4cd0-8c73-235a34035a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.count()\n",
    "# You can peek at the data too.\n",
    "# db.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e89f9dc-2396-4e24-96ad-f07c080703ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict, Any, Dict\n",
    "\n",
    "# Define the state of our graph\n",
    "class AgentState(TypedDict):\n",
    "    audio_file_path: Any\n",
    "    instructions: str\n",
    "    transcription: str\n",
    "    quest: Dict[str, Any]\n",
    "    medical_records: str\n",
    "    quest_resp: str\n",
    "    quest_found: bool\n",
    "    quest_resp_valid: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ce7795d-b5b6-4298-aaef-52da98512a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_workflow(state: AgentState):\n",
    "    \"\"\" \n",
    "    Start: preserves input prompt, which includes audio file and prompt instructions\n",
    "    \"\"\"\n",
    "    return {\"audio_file_path\": state[\"audio_file_path\"], \"instructions\": state[\"instructions\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556310e4-922c-461d-9e81-d67cc25e2d01",
   "metadata": {},
   "source": [
    "## Retrieval: Finding relevant questionnaires\n",
    "\n",
    "We can then use the prompt to get the questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46ebc9-0f57-4c98-b88f-e9ac9ddba8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "\n",
    "class RelevantRating(enum.Enum):\n",
    "    YES = \"Yes\"\n",
    "    NO = \"No\"\n",
    "\n",
    "\n",
    "def discover_questionnaire(query):\n",
    "    try:\n",
    "        embed_fn.document_mode = False\n",
    "        result = db.query(query_texts=[query], n_results=1)\n",
    "        queried_doc_ids = result.get(\"ids\")\n",
    "        try:\n",
    "            interest_doc_id = queried_doc_ids[0][0]\n",
    "        except IndexError:\n",
    "            return None\n",
    "        queried_doc_desc = result.get(\"documents\")[0][0]\n",
    "        queried_doc_meta = result.get(\"metadatas\")[0][0]\n",
    "\n",
    "        \n",
    "        print(result)\n",
    "        structured_output_config = types.GenerateContentConfig(\n",
    "            response_mime_type=\"text/x.enum\",\n",
    "            response_schema=RelevantRating,\n",
    "        )\n",
    "        response = gda_client.models.generate_content(\n",
    "            model=gda_client_model, contents=[prompt], config=structured_output_config\n",
    "        )\n",
    "        parsed_resp = response.parsed\n",
    "\n",
    "        if parsed_resp is RelevantRating.YES:\n",
    "            return interest_doc_id\n",
    "        else:\n",
    "            return\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_questionnaire(state: AgentState):\n",
    "    query = state.get(\"instructions\")\n",
    "    quest_id = discover_questionnaire(query)\n",
    "\n",
    "    full_quest_docs = read_questionnaires_from_store()\n",
    "    of_interest_quest = None\n",
    "    for quest in full_quest_docs:\n",
    "        if quest[\"id\"] == quest_id:\n",
    "            of_interest_quest = quest\n",
    "            break\n",
    "    if of_interest_quest is None:\n",
    "        return {\"quest_found\": False}\n",
    "    else:\n",
    "        return {\"quest_found\": True, \"quest\": of_interest_quest}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c6b6af-2f2a-4067-beb0-3477bce6ba25",
   "metadata": {},
   "source": [
    "Now that we have the questionnaire and the transcripted audio files, we can move on to generate the questionnaireResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7030480-db47-4d1c-8c63-fd7c3ee69096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_repair\n",
    "google_model_id = \"gemini-2.0-flash\"\n",
    "\n",
    "def generate_questresp(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Extract relevant information,\n",
    "    and return a FHIR QuestionnaireResponse resource as a dict.\n",
    "    \"\"\"\n",
    "    transcribed = state.get(\"transcription\")\n",
    "    questionnaire = state.get(\"quest\")\n",
    "    # 3. Prepare the LLM prompt\n",
    "    prompt = create_prompt_for_questionnaire_response(\n",
    "        transcribed, questionnaire\n",
    "    )\n",
    "\n",
    "    response = gda_client.models.generate_content(\n",
    "        model=google_model_id, contents=[prompt, transcribed], config={\n",
    "            'response_mime_type': 'application/json'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    qr_string = response.text.strip()\n",
    "    qr = json_repair.loads(qr_string)\n",
    "    # try:\n",
    "    #     questionnaire_response = json.loads(llm_output)\n",
    "    # except Exception as e:\n",
    "    #     raise ValueError(f\"Invalid JSON from LLM: {e}\")\n",
    "\n",
    "    # # 6. Validate the JSON against FHIR schema (optional but recommended)\n",
    "    # #    This step ensures the object meets the QuestionnaireResponse structure\n",
    "    # if not validate_fhir_questionnaire_response(questionnaire_response):\n",
    "    #     raise ValueError(\"Generated QuestionnaireResponse is not valid FHIR.\")\n",
    "\n",
    "    # # 7. Return or store the final resource\n",
    "    return {\"quest_resp\": qr}\n",
    "\n",
    "\n",
    "def create_prompt_for_questionnaire_response(\n",
    "    cleaned_text: str, questionnaire_template: dict\n",
    ") -> str:\n",
    "    # Construct a system/user prompt with instructions,\n",
    "    # referencing relevant sections of the conversation\n",
    "    prompt = f\"\"\"\n",
    "    You are a medical documentation assistant.\n",
    "    Below is a transcribed patient-physician conversation:\n",
    "    ---\n",
    "    {cleaned_text}\n",
    "    ---\n",
    "\n",
    "    You have a FHIR Questionnaire defined as follows:\n",
    "    {json.dumps(questionnaire_template, indent=2)}\n",
    "\n",
    "    Extract the relevant data from the conversation to populate a FHIR QuestionnaireResponse\n",
    "    based on the provided Questionnaire. Return ONLY valid JSON representing this \n",
    "    QuestionnaireResponse with fields \"resourceType\": \"QuestionnaireResponse\", \n",
    "    \"questionnaire\": \"<Questionnaire-identifier>\",\n",
    "    \"status\", \"subject\", \"authored\", \"item\", etc.\n",
    "\n",
    "    If a field is unknown, leave it blank or null. \n",
    "    Do not add additional commentary.\n",
    "\n",
    "    Use this JSON schema:\n",
    "\n",
    "    QuestionnaireResponse = <generated questionnaireResponse>\n",
    "    return: QuestionnaireResponse\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af628e5f-1b4e-4f11-a4a6-006f2a62ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_qr(state: AgentState):\n",
    "#     qr = state.get(\"quest_resp\")\n",
    "#     # use a publicly available fhir instance.\n",
    "#     url = f\"{QUESTIONNAIRE_ENDPOINT}/$validate\"\n",
    "#     headers = {\"Content-Type\": \"application/fhir+json\"}\n",
    "\n",
    "#     response = requests.post(url, json=qr, headers=headers)\n",
    "#     if response.ok:\n",
    "#         return {\"quest_resp_valid\": True}\n",
    "#     else:\n",
    "#         return {\"quest_resp_valid\": False}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b21fbad-fae6-4732-acee-9c0d8481215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_questionnaire_response(state: AgentState) -> str:\n",
    "#     \"\"\"\n",
    "#     Saves the validated QuestionnaireResponse to the HAPI FHIR server.\n",
    "\n",
    "#     Args:\n",
    "#         questionnaire_response (Dict): The validated FHIR QuestionnaireResponse in JSON format.\n",
    "\n",
    "#     Returns:\n",
    "#         str: A success message or an error message if saving fails.\n",
    "#     \"\"\"\n",
    "#     quest_resp = state.get(\"quest_resp\")\n",
    "#     print(\"\\n\\n\\n\\n\",quest_resp, type(quest_resp))\n",
    "#     questionnaire_response_endpoint = f\"{HAPI_FHIR_BASE_URL}/QuestionnaireResponse\"\n",
    "#     headers = {\"Accept\": \"application/fhir+json\", \"Content-Type\": \"application/fhir+json\"}\n",
    "\n",
    "#     response = requests.post(questionnaire_response_endpoint, headers=headers, json=quest_resp)\n",
    "#     response.raise_for_status() # Raise exception for HTTP errors\n",
    "\n",
    "#     if response.status_code in range(200, 300):\n",
    "#         created_resource = response.json()\n",
    "#         return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad8a1adf-245d-4ab1-a197-c144bb5d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transcription Function ---\n",
    "# TODO - why do we need to this.\n",
    "def diarize_audio(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transcribes the given audio file using the Gemini model, aiming for a\n",
    "    conversation-style output with speaker labels.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized Gemini GenerativeModel instance.\n",
    "        audio_file_path: Path to the audio file (e.g., .wav, .mp3, .flac).\n",
    "    \"\"\"\n",
    "    # TODO - check that audio format is supported.\n",
    "    uploaded_file = state[\"audio_file_path\"]\n",
    "\n",
    "    \n",
    "    # 2. Construct the Prompt - Key Considerations for Conversation Style:\n",
    "    #    - Explicitly ask for transcription.\n",
    "    #    - Request speaker diarization (identifying and labeling speakers).\n",
    "    #    - Suggest common labels (like 'Doctor:', 'Patient:', or 'Speaker 1:', 'Speaker 2:').\n",
    "    #    - Ask for natural punctuation and formatting.\n",
    "    #    - Specify how to handle non-speech sounds (ignore, note in brackets, etc.).\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Diarize and transcribe this health-related interview, maintaining chronological order with timestamps if possible. Add labels for speaker (like 'Doctor:', 'Patient:', or 'Speaker 1:', 'Speaker 2:') at the beginning of each turn.\n",
    "    Accurately capture medical terms, mark unclear words as “[INAUDIBLE],” avoid adding extra commentary or guesses, and keep overlapping speech on separate lines. \n",
    "    Return only the final transcript.\n",
    "    \"\"\"\n",
    "\n",
    "    response = gda_client.models.generate_content(\n",
    "        model=google_model_id,\n",
    "        contents = [prompt, uploaded_file]\n",
    "    )\n",
    "\n",
    "    transcription = response.text.strip()\n",
    "    return {\"transcription\": transcription}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2cb0d9c-0d11-4c0c-b0bf-289f47d089d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_workflow(state: AgentState):\n",
    "    # TODO - \n",
    "    print(\"Workflow end\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0977e35d-093d-41d8-a84a-11497c240bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI # Correct import path\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "# from langgraph.pregel import PregelProcess # TODO???\n",
    "\n",
    "model_id = \"gemini-2.0-flash\"\n",
    "model = ChatGoogleGenerativeAI(model=model_id, google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Defined the graph\n",
    "wk_graph = StateGraph(AgentState)\n",
    "\n",
    "# Nodes\n",
    "wk_graph.add_node(\"discover_and_fetch_questionnaire\", fetch_questionnaire)\n",
    "wk_graph.add_node(\"transcribe_audio\", diarize_audio)\n",
    "wk_graph.add_node(\"generate_questionnaire_response\", generate_questresp)\n",
    "# wk_graph.add_node(\"save_response\", save_questionnaire_response) \n",
    "wk_graph.add_node(\"terminate_workflow\", terminate_workflow)\n",
    "\n",
    "# Edges\n",
    "wk_graph.add_edge(START, \"discover_and_fetch_questionnaire\")\n",
    "wk_graph.add_conditional_edges(\n",
    "    \"discover_and_fetch_questionnaire\",\n",
    "    lambda state: [\n",
    "        \"generate_questionnaire_response\",\n",
    "        \"generate_soap_note\"\n",
    "    ] if state[\"quest_found\"] else \"terminate_workflow\"\n",
    ")\n",
    "# wk_graph.add_conditional_edges(\"discover_and_fetch_questionnaire\", lambda state: \"transcribe_audio\" if state[\"quest_found\"] else \"terminate_workflow\")\n",
    "wk_graph.add_edge(\"transcribe_audio\", \"generate_questionnaire_response\")\n",
    "wk_graph.add_edge(\"generate_questionnaire_response\", \"terminate_workflow\")\n",
    "wk_graph.add_edge(\"terminate_workflow\", END)\n",
    "\n",
    "\n",
    "\n",
    "graph = wk_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8fa31d2-eeef-4862-b25b-2450610b75f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1da3816a-4851-4231-b456-91d167fb6426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.9071840643882751]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "Workflow end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "local_input_file_url = \"./Data/Audio Recordings/CAR0002.mp3\"\n",
    "uploaded_file_uri = gda_client.files.upload(file=local_input_file_url)\n",
    "\n",
    "inputs = {\"audio_file_path\": uploaded_file_uri, \"instructions\": \"Process audio and fill out a medical history report\"}\n",
    "result = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67caa6e-e2eb-4fbb-80d4-c649ae61d2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
