{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Clinical Documentation Assistant\n",
    "\n",
    "## Problem overview\n",
    "\n",
    "Healthcare professionals face a significant burden from medical documentation. This project focuses on leveraging generative AI to alleviate this burden by automatically extracting structured information from physician-patient audio conversations and using it to pre-fill administrative forms by generating data points that can be electronically stored in EMRs, and EHRS.\n",
    "\n",
    "We particularly focus on how the below presented workflow can be used to fill a medical history form an audio recording.\n",
    "\n",
    "This tool outputs data in a FHIR compatible format which ensures seamless integration with existing healthcare systems through a standardized, interoperable format. This structured approach unlocks the data's potential for reusability in various clinical workflows, analytics, and future healthcare applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution architecture\n",
    "\n",
    "This tool implements a RAG-based approach for form/[questionaire](https://www.hl7.org/fhir/R4/questionnaireresponse.html) discovery depending on a users prompt.\n",
    "\n",
    "It then generates a [QuestionnaireResponse](https://www.hl7.org/fhir/R4/questionnaireresponse.html), which represents an instance of a form submission\n",
    "\n",
    "In the place of FHIR compatible server we use a json file placeholder to act as a questionnaire repository\n",
    "\n",
    "[TODO - insert workflow image here preferably landscape]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Set up your API key**\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T10:35:14.606725Z",
     "iopub.status.busy": "2025-04-16T10:35:14.606413Z",
     "iopub.status.idle": "2025-04-16T10:35:15.297735Z",
     "shell.execute_reply": "2025-04-16T10:35:15.297068Z",
     "shell.execute_reply.started": "2025-04-16T10:35:14.606698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "model_id = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-16T10:35:10.934524Z",
     "iopub.status.busy": "2025-04-16T10:35:10.933821Z",
     "iopub.status.idle": "2025-04-16T10:35:14.604208Z",
     "shell.execute_reply": "2025-04-16T10:35:14.603220Z",
     "shell.execute_reply.started": "2025-04-16T10:35:10.934498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "%pip install -U -q \"google-genai==1.7.0\"\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.api_core import retry\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "**Creating the embedding database with ChromaDB**\n",
    "\n",
    "We create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. \n",
    "\n",
    "We will use this to store our questionnaire description as documents in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:41:15.523141Z",
     "iopub.status.busy": "2025-04-16T14:41:15.522788Z",
     "iopub.status.idle": "2025-04-16T14:41:24.082104Z",
     "shell.execute_reply": "2025-04-16T14:41:24.081034Z",
     "shell.execute_reply.started": "2025-04-16T14:41:15.523077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h^C\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the chromadb package\n",
    "%pip install -qU \"chromadb==0.6.3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        response = gda_client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=embedding_task,\n",
    "            ),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a few utils that will be used to load the json questionnaire data. Ideally the data source would be a live FHIR server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "_quest_docs = None\n",
    "def read_questionnaires_from_fs():\n",
    "    global _quest_docs\n",
    "    if _quest_docs is None:\n",
    "        with open(\"./quest.db.json\", \"r\") as file:\n",
    "            _quest_docs = json.loads(file.read())\n",
    "    return _quest_docs\n",
    "\n",
    "def get_quest_docs_meta():\n",
    "    quest_docs = read_questionnaires_from_fs()\n",
    "    doc_with_metad = []\n",
    "    doc_ids = []\n",
    "    for doc in quest_docs:\n",
    "        doc_id = doc.get(\"id\")\n",
    "        doc_meta = {\n",
    "            k: v\n",
    "            for k, v in {\n",
    "                \"id\": doc_id,\n",
    "                \"title\": doc.get(\"title\"),\n",
    "                \"name\": doc.get(\"name\"),\n",
    "            }.items()\n",
    "            if v is not None\n",
    "        }\n",
    "        doc_desc = (\n",
    "            doc.get(\"description\") if doc.get(\"description\") else \"No description\"\n",
    "        )\n",
    "        doc_with_metad.append((doc_desc, doc_meta))\n",
    "        doc_ids.append(doc_id)\n",
    "    return doc_with_metad, doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load our questionnaire data and populate the vector database. we store the descriptions as vector embeddings and tag it with some metadata pertaining to each form/questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"fhir-quest-semantic\"\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "def populate_vector_db():\n",
    "    embed_fn.document_mode = True\n",
    "    (desc_with_metad, doc_ids) = get_quest_docs_meta()\n",
    "    descriptions, meta = zip(*desc_with_metad)\n",
    "    print(meta)\n",
    "\n",
    "    db.add(documents=list(descriptions), ids=doc_ids, metadatas=list(meta))\n",
    "\n",
    "populate_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the data was inserted by looking at the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval: Finding relevant questionnaires\n",
    "\n",
    "We will be using the user prompt to find a relevant questionnaire to fill. We do so by\n",
    "\n",
    "1. Querying our vector store for the single top most questionnaire that is semantically related to the users needs\n",
    "2. Use the gemini model to validate that the questionnaire does actually relate to the users prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_form_validation_prompt(user_prompt, quest_desc, quest_metadata):\n",
    "    return \"\"\"\\\n",
    "# Instruction\n",
    "You are an expert evaluator. Your task is to evaluate the relevance of a form description and metadata to a user instruction.\n",
    "We will provide you with the user instruction, and the form description and metadata.\n",
    "Read the user instruction carefully to understand the user's need, and then evaluate if the provided form description and metadata are relevant to fulfilling that need based on the Criteria provided in the Evaluation section below.\n",
    "You will assign the form description a rating following the Rating Rubric\n",
    "\n",
    "# Evaluation\n",
    "## Metric Definition\n",
    "You will be assessing form relevance, which measures whether the provided form description and metadata are suitable for fulfilling the user's instruction.  Relevance implies that a user could likely find the form useful and pertinent to their stated need.\n",
    "\n",
    "## Criteria\n",
    "Relevance to User Instruction: The form description and metadata align with the user's instruction and suggest the form could potentially address the user's need.\n",
    "Usefulness for User Instruction: The form, as described, appears practically useful for a user attempting to follow the given instruction.\n",
    "Clarity of Description: The form description and metadata are clear and understandable enough to assess relevance. (If description is unclear, down-rate even if potentially relevant).\n",
    "\n",
    "## Rating Rubric\n",
    "(YES). The form is very likely to be relevant and useful for the user instruction. The description is clear and strongly suggests a good match.\n",
    "(NO). The form is not relevant to the user instruction. The description clearly indicates the form is unrelated to the user's need.\n",
    "\n",
    "# User Inputs and Model Rating\n",
    "## User Instruction\n",
    "\n",
    "### Prompt\n",
    "{query}\n",
    "\n",
    "## Form Description and Metadata\n",
    "\n",
    "### Form Instruction Description\n",
    "{queried_doc_desc}\n",
    "\n",
    "### Form Metadata (JSON)\n",
    "{queried_doc_meta}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use JSON mode to control the models output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "\n",
    "class RelevantRating(enum.Enum):\n",
    "    YES = \"Yes\"\n",
    "    NO = \"No\"\n",
    "\n",
    "def discover_questionnaire(query):\n",
    "    embed_fn.document_mode = False\n",
    "    result = db.query(query_texts=[query], n_results=1)\n",
    "    queried_doc_ids = result.get(\"ids\")\n",
    "    try:\n",
    "        interest_doc_id = queried_doc_ids[0][0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "    queried_doc_desc = result.get(\"documents\")[0][0]\n",
    "    queried_doc_meta = result.get(\"metadatas\")[0][0]\n",
    "\n",
    "    structured_output_config = types.GenerateContentConfig(\n",
    "        response_mime_type=\"text/x.enum\",\n",
    "        response_schema=RelevantRating,\n",
    "    )\n",
    "    response = gda_client.models.generate_content(\n",
    "        model=gda_client_model, contents=[prompt], config=structured_output_config\n",
    "    )\n",
    "    parsed_resp = response.parsed\n",
    "\n",
    "    if parsed_resp is RelevantRating.YES:\n",
    "        return interest_doc_id\n",
    "    else:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our agent's internal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install -qU \"langchain==0.3.23\" \"langgraph==0.3.29\" \"json-repair==0.41.1\" \"langchain-google-genai==2.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T15:19:56.022373Z",
     "iopub.status.busy": "2025-04-16T15:19:56.021656Z",
     "iopub.status.idle": "2025-04-16T15:19:57.911877Z",
     "shell.execute_reply": "2025-04-16T15:19:57.911047Z",
     "shell.execute_reply.started": "2025-04-16T15:19:56.022348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict, Any, Dict\n",
    "\n",
    "# Define the state of our graph\n",
    "class AgentState(TypedDict):\n",
    "    local_audio_file_path: str\n",
    "    uploaded_audio_file: Any\n",
    "    instructions: str\n",
    "    quest: Dict[str, Any]\n",
    "    medical_records: Dict[str, Any]\n",
    "    quest_resp: str\n",
    "    quest_found: bool\n",
    "    quest_resp_valid: bool\n",
    "    soap_note: str\n",
    "    soap_note_sample: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fetch_questionnaire(state: AgentState):\n",
    "    query = state.get(\"instructions\")\n",
    "    quest_id = discover_questionnaire(query)\n",
    "\n",
    "    full_quest_docs = read_questionnaires_from_fs()\n",
    "    of_interest_quest = None\n",
    "    for quest in full_quest_docs:\n",
    "        if quest[\"id\"] == quest_id:\n",
    "            of_interest_quest = quest\n",
    "            break\n",
    "    if of_interest_quest is None:\n",
    "        return {\"quest_found\": False}\n",
    "    else:\n",
    "        return {\"quest_found\": True, \"quest\": of_interest_quest}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make make the call to the model with the questionniare that describes the form, and the audio file expecting the qeustionnaire response. The questionnaire response represents the form submission that a physician would have had to make manually from listening or partaking in the recorded conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T10:35:15.298951Z",
     "iopub.status.busy": "2025-04-16T10:35:15.298624Z",
     "iopub.status.idle": "2025-04-16T10:35:15.305786Z",
     "shell.execute_reply": "2025-04-16T10:35:15.305096Z",
     "shell.execute_reply.started": "2025-04-16T10:35:15.298925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from json_repair import repair_json\n",
    "\n",
    "def upload_to_gemini(state: AgentState):\n",
    "    \"\"\"Uploads the given file to Gemini.\"\"\"\n",
    "    local_file_path = state.get(\"local_audio_file_path\")\n",
    "    try:\n",
    "        file = client.files.upload(file=local_file_path)\n",
    "        return {\"uploaded_audio_file\": file}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # TODO - what should happen here?\n",
    "        return {}\n",
    "\n",
    "def get_questionnaire_response(state: AgentState):\n",
    "    audio_file = state.get(\"uploaded_audio_file\")\n",
    "    questionnaire = state.get(\"quest\")\n",
    "    patient_emr = None # state.get(\"patient_emr\")\n",
    "    # patient_emr, audio_file, questionnaire, questionnaireRes_example\n",
    "    prompt = f\"\"\"\n",
    "        You are an audio processing expert with extensive experience in converting audio files into structured data formats, specifically JSON. Your specialty lies in accurately extracting meaningful information from audio recordings and populating questionnaire-style data structures based on that information.\n",
    "        \n",
    "        Your task is to analyze the provided audio file and patient Electronic Medical Record (EMR) and fill out the questionnaire with the relevant responses. The output format should follow the structure of the provided questionnaireResponse example.\n",
    "\n",
    "        Here is the patient EMR:\n",
    "        {patient_emr}\n",
    "        \n",
    "        Here is the questionnaire:\n",
    "        {questionnaire}\n",
    "        \n",
    "        Here is an example questionnaire response:\n",
    "        {questionnaireRes_example}\n",
    "        \n",
    "        Please analyze the audio and generate the appropriate questionnaire response.\n",
    "\n",
    "        Use this JSON schema:\n",
    "\n",
    "        QuestionnaireResponse = <generated questionnaireResponse>\n",
    "        return: QuestionnaireResponse\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id,\n",
    "        contents=[prompt, audio_file],\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0,\n",
    "            response_mime_type='application/json',\n",
    "        )\n",
    "    )\n",
    "    qr = repair_json.loads(response.text)\n",
    "    return {\"quest_resp\": qr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T10:35:15.309886Z",
     "iopub.status.busy": "2025-04-16T10:35:15.309629Z",
     "iopub.status.idle": "2025-04-16T10:35:15.324526Z",
     "shell.execute_reply": "2025-04-16T10:35:15.323633Z",
     "shell.execute_reply.started": "2025-04-16T10:35:15.309868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_soap_note_from_audio(state: AgentState):\n",
    "    patient_emr = None # state.get(\"patient_emr\")\n",
    "    audio_file = audio_file = state.get(\"uploaded_audio_file\")\n",
    "    soap_note_sample = state.get(\"soap_note_sample\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a clinical documentation specialist with expertise in converting clinical conversations and EMRs into SOAP notes.\n",
    "\n",
    "    Your task is to analyze the provided audio file and patient EMR to create a well-structured SOAP note.\n",
    "\n",
    "    Follow the SOAP format strictly:\n",
    "    - **Subjective (S):** Patient's stated symptoms and complaints\n",
    "    - **Objective (O):** Measurable/observable data such as vital signs or physical exam findings\n",
    "    - **Assessment (A):** Clinical impressions and diagnoses\n",
    "    - **Plan (P):** Treatment plans, follow-up, and recommendations\n",
    "\n",
    "    Here is the patient's EMR:\n",
    "    {patient_emr}\n",
    "\n",
    "    Here is an example SOAP note:\n",
    "    {soap_note_sample}\n",
    "\n",
    "    Please create the SOAP note based on the audio and EMR.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id,\n",
    "        contents=[prompt, audio_file],\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0.1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return {\"soap_note\": response.text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T10:35:15.326027Z",
     "iopub.status.busy": "2025-04-16T10:35:15.325803Z",
     "iopub.status.idle": "2025-04-16T10:35:15.343143Z",
     "shell.execute_reply": "2025-04-16T10:35:15.342454Z",
     "shell.execute_reply.started": "2025-04-16T10:35:15.326010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_outputs(state: AgentState):\n",
    "    # patient_emr, audio_file, questionnaire_response, soap_note, questionnaire_example, soap_example\n",
    "    patient_emr = None # state.get(\"patient_emr\")\n",
    "    audio_file = state.get(\"uploaded_audio_file\")\n",
    "    questionnaire_response = state.get(\"quest_resp\")\n",
    "    soap_note = state.get(\"soap_note\")\n",
    "    questionnaire_example = state.get(\"quest\")\n",
    "    soap_note_sample = state.get(\"soap_note_sample\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a medical evaluator tasked with reviewing clinical documentation.\n",
    "\n",
    "    You will evaluate:\n",
    "    1. The quality and completeness of a **Questionnaire Response**\n",
    "    2. The accuracy and structure of a **SOAP Note**\n",
    "\n",
    "    @Lakshay - TODO - what does quality, accuracy and structure look like???\n",
    "    Use the following scale:\n",
    "    - 5 = Very Good\n",
    "    - 4 = Good\n",
    "    - 3 = Acceptable\n",
    "    - 2 = Poor\n",
    "    - 1 = Very Poor\n",
    "    - 0 = Unusable\n",
    "\n",
    "    Base your evaluation on:\n",
    "    - Clinical relevance and coherence\n",
    "    - Completeness compared to examples\n",
    "    - Consistency with the patient EMR\n",
    "\n",
    "    --- Patient EMR (for reference) ---\n",
    "    {patient_emr}\n",
    "\n",
    "    --- Audio Transcript of patient and Doctor Conversation (for reference) ---\n",
    "    {audio_file}\n",
    "\n",
    "    --- Example Questionnaire Response ---\n",
    "    {questionnaire_example}\n",
    "\n",
    "    --- Given Questionnaire Response ---\n",
    "    {questionnaire_response}\n",
    "\n",
    "    --- Example SOAP Note ---\n",
    "    {soap_note_sample}\n",
    "\n",
    "    --- Given SOAP Note ---\n",
    "    {soap_note}\n",
    "\n",
    "    Now provide a rating for each of the following:\n",
    "    1. Questionnaire Response (0–5):\n",
    "    2. SOAP Note (0–5):\n",
    "\n",
    "    Include a one-sentence rationale for each score.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id,\n",
    "        contents=[prompt],\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text: str, n: int = 50) -> str:\n",
    "    \"\"\"Truncates text to the first n characters, adding ellipsis if truncated.\"\"\"\n",
    "    if len(text) > n:\n",
    "        return text[:n] + \"...\"\n",
    "    return text\n",
    "\n",
    "def write_response(state: AgentState):\n",
    "    \"\"\"\n",
    "    Writes a response to the user based on the agent's state, reporting the outcome\n",
    "    of the workflow.\n",
    "\n",
    "    This function serves as the reporting node in the LangGraph workflow. It examines\n",
    "    the AgentState to determine the success or failure\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent, containing information\n",
    "                            about the workflow execution, including questionnaire\n",
    "                            response and SOAP note.\n",
    "    \"\"\"\n",
    "    quest_resp = state.get(\"quest_resp\")\n",
    "    soap_note = state.get(\"soap_note\")\n",
    "    quest_found = state.get(\"quest_found\")\n",
    "\n",
    "    if quest_resp is None or soap_note is None:\n",
    "        error_message = \"Workflow encountered an issue.\"\n",
    "        if not quest_found:\n",
    "            error_message += \" It appears there was a problem finding relevant questionnaire information. \"\n",
    "        if quest_resp is None:\n",
    "            error_message += \"Questionnaire Response was not generated. \"\n",
    "        if soap_note is None:\n",
    "            error_message += \"SOAP Note was not generated.\"\n",
    "        print(error_message)\n",
    "    else:\n",
    "        truncated_quest_resp = truncate_text(json.dumps(quest_resp, indent=2))\n",
    "        truncated_soap_note = truncate_text(soap_note)\n",
    "\n",
    "        success_message = \"Workflow completed successfully!\\n\\n\"\n",
    "        success_message += \"**Questionnaire Response:**\\n\"\n",
    "        success_message += truncated_quest_resp + \"\\n\\n\"\n",
    "        success_message += \"**SOAP Note:**\\n\"\n",
    "        success_message += truncated_soap_note\n",
    "        print(success_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring everything together as a graph to execture our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI # Correct import path\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=model_id, google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Defined the graph\n",
    "wk_graph = StateGraph(AgentState)\n",
    "\n",
    "def state_aggregator(state: StateGraph):\n",
    "    return state\n",
    "\n",
    "# node magic strings\n",
    "upload_to_gemini = \"upload_file_to_gemini\"\n",
    "disc_fetch_questionnaire = \"discover_and_fetch_questionnaire\"\n",
    "gen_quest_resp = \"generate_questionnaire_response\"\n",
    "gen_soap_note = \"generate_soap_note\"\n",
    "eval_outputs = \"evaluate_outputs\"\n",
    "write_resp = \"write_resp\"\n",
    "state_aggregator = \"state_aggregator\"\n",
    "\n",
    "# Nodes\n",
    "wk_graph.add_node(upload_to_gemini, upload_to_gemini)\n",
    "wk_graph.add_node(disc_fetch_questionnaire, fetch_questionnaire)\n",
    "wk_graph.add_node(gen_quest_resp, get_questionnaire_response)\n",
    "wk_graph.add_node(gen_soap_note, generate_soap_note_from_audio)\n",
    "wk_graph.add_note(eval_outputs, evaluate_outputs)\n",
    "wk_graph.add_note(write_resp, write_response)\n",
    "wk_graph.add_node(state_aggregator, state_aggregator)\n",
    "\n",
    "# Edges\n",
    "wk_graph.add_edge(START, upload_to_gemini)\n",
    "wk_graph.add_edge(START, disc_fetch_questionnaire)\n",
    "wk_graph.add_edge(upload_to_gemini, lambda state: state_aggregator if state[\"uploaded_audio_file\"] else write_resp)\n",
    "wk_graph.add_edge(disc_fetch_questionnaire, state_aggregator)\n",
    "wk_graph.add_conditional_edges(state_aggregator, lambda state: gen_soap_note if state[\"quest_found\"] else write_resp)\n",
    "wk_graph.add_edge(state_aggregator, gen_soap_note)\n",
    "wk_graph.add_edge(gen_soap_note, state_aggregator)\n",
    "wk_graph.add_edge(gen_quest_resp, state_aggregator)\n",
    "wk_graph.add_edge(state_aggregator, write_resp)\n",
    "wk_graph.add_edge(write_resp, END)\n",
    "\n",
    "graph = wk_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "audio_file_path = '/kaggle/input/conversation/RES0005.mp3'\n",
    "patient_emr_path = '/kaggle/input/conversation/PatientEMR.json'\n",
    "soap_ex_path = '/kaggle/input/conversation/soap_example.txt'\n",
    "# ques_path = '/kaggle/input/conversation/Questionnaire.json'\n",
    "# qRes_path = '/kaggle/input/conversation/QuestionnaireResponse.json'\n",
    "\n",
    "\n",
    "with open(soap_ex_path, 'r') as f:\n",
    "    soap_example = f.read()\n",
    "\n",
    "# with open(patient_emr_path, 'r') as f:\n",
    "#     patient_emr = f.read()\n",
    "\n",
    "# with open(ques_path, 'r') as f:\n",
    "#     questionnaire = f.read()\n",
    "\n",
    "# with open(qRes_path, 'r') as f:\n",
    "#     questionnaireRes_example = f.read()\n",
    "\n",
    "local_input_file_url = \"./Data/Audio Recordings/CAR0002.mp3\"\n",
    "inputs = {\n",
    "    \"local_audio_file_path\": audio_file_path,\n",
    "    \"instructions\": \"Fill out a medical history report\",\n",
    "    \"soap_note_sample\": soap_example,\n",
    "}\n",
    "graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T10:35:15.344143Z",
     "iopub.status.busy": "2025-04-16T10:35:15.343915Z",
     "iopub.status.idle": "2025-04-16T10:35:35.216230Z",
     "shell.execute_reply": "2025-04-16T10:35:35.215478Z",
     "shell.execute_reply.started": "2025-04-16T10:35:15.344125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'None' as: https://generativelanguage.googleapis.com/v1beta/files/zm39zbh444d9\n",
      "name='files/zm39zbh444d9' display_name=None mime_type='audio/mpeg' size_bytes=5360385 create_time=datetime.datetime(2025, 4, 16, 10, 35, 16, 855820, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 4, 18, 10, 35, 16, 814882, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 4, 16, 10, 35, 16, 855820, tzinfo=TzInfo(UTC)) sha256_hash='NDE4YTgyYzdmZDY5MjIwNzUyMjRhZjVjNDA1YzkxOTMyMDc3ZWQ4MjU2YjhiODBkMzVjYWI4YzU1ZjA5OGFlNw==' uri='https://generativelanguage.googleapis.com/v1beta/files/zm39zbh444d9' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "{\n",
      "  \"resourceType\": \"QuestionnaireResponse\",\n",
      "  \"id\": \"46984394\",\n",
      "  \"meta\": {\n",
      "    \"versionId\": \"1\",\n",
      "    \"lastUpdated\": \"2025-04-12T20:31:18.164+00:00\",\n",
      "    \"source\": \"#FFJBMqq4kXSicAF5\"\n",
      "  },\n",
      "  \"questionnaire\": \"Questionnaire/health-history-questionnaire-2021-06\",\n",
      "  \"status\": \"completed\",\n",
      "  \"authored\": \"2023-10-26\",\n",
      "  \"item\": [\n",
      "    {\n",
      "      \"linkId\": \"patientInformation\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"patientName\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueString\": \"Roel Bor\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"patientDOB\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueDate\": \"1960-03-13\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"mainReasonForVisit\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueString\": \"cough with blood in sputum\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"socialHistory\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"occupation\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueString\": \"retired\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"maritalStatus\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"married\",\n",
      "                \"display\": \"Married\"\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"smokingStatus\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"current\",\n",
      "                \"display\": \"Current\"\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"numCigarettesPerDay\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueInteger\": 20\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"numYearsSmoking\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueInteger\": 40\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"linkId\": \"alcoholDrinksPerWeek\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueInteger\": 2\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"currentMedications\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"medicationList\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueString\": \"Rosuvastatin\"\n",
      "            },\n",
      "            {\n",
      "              \"valueString\": \"Blood pressure medication\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"medicationAllergies\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"anyMedicationAllergies\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueBoolean\": false\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"pastMedicalHistory\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"conditionsList\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"lung-disease\",\n",
      "                \"display\": \"Lung Disease/Pneumonia\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"high-blood-pressure\",\n",
      "                \"display\": \"High Blood Pressure\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"high-cholesterol\",\n",
      "                \"display\": \"High Cholesterol\"\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"healthScreenings\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"screeningNone\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueBoolean\": true\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"hospitalizations\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"hospitalNone\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueBoolean\": true\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"surgicalProcedures\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"surgeryNone\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueBoolean\": true\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"linkId\": \"familyHistory\",\n",
      "      \"item\": [\n",
      "        {\n",
      "          \"linkId\": \"conditionsList\",\n",
      "          \"answer\": [\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"heart-attack\",\n",
      "                \"display\": \"Heart Attack\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"arthritis\",\n",
      "                \"display\": \"Arthritis\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"valueCoding\": {\n",
      "                \"code\": \"cancer\",\n",
      "                \"display\": \"Cancer\"\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Okay, here is the SOAP note based on the provided audio and EMR:\n",
      "\n",
      "**SOAP Note**\n",
      "\n",
      "**Patient:** Roel Bor\n",
      "**DOB:** 1960-03-13\n",
      "**MRN:** 123456789\n",
      "\n",
      "**S: Subjective**\n",
      "\n",
      "*   **Chief Complaint (CC):** \"I've been having a cough for around two years which has been getting worse, but recently I've noticed streaks of blood in the sputum that I'm producing.\"\n",
      "*   **History of Present Illness (HPI):**\n",
      "\n",
      "    *   The patient is a 63-year-old male who reports a two-year history of a gradually worsening cough.\n",
      "    *   He notes that the cough has become more frequent and severe.\n",
      "    *   Recently (over the last two months), he has noticed occasional streaks of blood in his sputum, which was previously white.\n",
      "    *   He estimates bringing up about a couple of teaspoons of sputum per day.\n",
      "    *   The cough is worse with activity and during viral infections.\n",
      "*   **Past Medical History (PMH):**\n",
      "\n",
      "    *   COPD\n",
      "    *   Chronic Bronchitis\n",
      "    *   Hypertension\n",
      "    *   Hypercholesterolemia\n",
      "*   **Medications:**\n",
      "\n",
      "    *   Rosuvastatin for cholesterol\n",
      "    *   Medication for blood pressure (unspecified, but well-controlled)\n",
      "    *   Previously used inhalers for COPD but has not used them in over 10 years.\n",
      "*   **Allergies:** No known allergies.\n",
      "*   **Social History:**\n",
      "\n",
      "    *   Smokes approximately 20 cigarettes per day (previously up to 30). Has been smoking for almost 40 years.\n",
      "    *   Does not use cannabis.\n",
      "    *   Drinks alcohol a couple of times a month.\n",
      "    *   Retired, previously worked in a steel factory.\n",
      "    *   Reports possible exposure to chemicals, dust particles, and potentially asbestos during his work history and in older buildings where he lived.\n",
      "    *   Lives alone in an apartment.\n",
      "*   **Family History:**\n",
      "\n",
      "    *   Father passed away from a heart attack in his 60s.\n",
      "    *   Mother had arthritis.\n",
      "    *   One uncle had bladder cancer.\n",
      "*   **Review of Systems (ROS):**\n",
      "\n",
      "    *   Reports increased fatigue throughout the day.\n",
      "    *   Reports increased breathlessness on exertion.\n",
      "    *   Denies fever, chills, night sweats, headaches, chest pain, heart palpitations, runny nose, sore throat, loss of smell or taste, abdominal pain, urinary problems, bowel problems, skin rashes, joint or muscle pains, or weakness.\n",
      "    *   Reports significant weight loss (8-10 pounds) in the last 1.5 months without trying.\n",
      "    *   Reports decreased ability to walk due to shortness of breath and coughing.\n",
      "*   **Patient Concerns:** Expresses concern about the possibility of cancer, particularly lung cancer, given his smoking history and the presence of blood in his sputum.\n",
      "\n",
      "**O: Objective**\n",
      "\n",
      "*   (Note: No objective data such as vital signs or physical exam findings were provided in the audio or EMR. This section would typically include information gathered during the physical examination.)\n",
      "\n",
      "**A: Assessment**\n",
      "\n",
      "*   **Primary Concern:** Hemoptysis in the setting of chronic cough, COPD, chronic bronchitis, smoking history, and weight loss.\n",
      "*   **Differential Diagnoses:**\n",
      "\n",
      "    *   Lung cancer\n",
      "    *   Exacerbation of COPD/Chronic Bronchitis\n",
      "    *   Pneumonia (including fungal)\n",
      "    *   Bronchiectasis\n",
      "    *   Tuberculosis\n",
      "    *   Asbestosis/Pulmonary Fibrosis\n",
      "\n",
      "**P: Plan**\n",
      "\n",
      "1.  **Diagnostic Testing:**\n",
      "\n",
      "    *   Order a chest CT scan to evaluate for lung masses, infection, or other structural abnormalities.\n",
      "    *   Order CBC and electrolytes.\n",
      "    *   Obtain an ECG to assess cardiac function.\n",
      "2.  **Management:**\n",
      "\n",
      "    *   Advise patient to quit smoking and provide resources for smoking cessation.\n",
      "    *   Monitor patient's respiratory status and oxygen saturation.\n",
      "3.  **Follow-Up:**\n",
      "\n",
      "    *   Schedule a follow-up appointment to discuss the results of the diagnostic testing and determine further management.\n",
      "    *   Instruct the patient to return to the clinic sooner if symptoms worsen or if he experiences increased shortness of breath, chest pain, or significant hemoptysis.\n",
      "4.  **Patient Education:**\n",
      "\n",
      "    *   Educate the patient about the potential causes of hemoptysis and the importance of diagnostic testing.\n",
      "    *   Discuss the risks of smoking and the benefits of smoking cessation.\n",
      "    *   Advise the patient on strategies to manage his COPD symptoms.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Here's the evaluation of the provided documents:\n",
      "\n",
      "1.  **Questionnaire Response (4):** The questionnaire response is good because it captures relevant patient information, including the chief complaint, social history, medications, and past medical history, and it is consistent with the patient EMR.\n",
      "\n",
      "2.  **SOAP Note (4):** The SOAP note is good because it presents a structured overview of the patient's condition, including subjective complaints, a differential diagnosis, and a reasonable plan, and it is consistent with the patient EMR.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     # File paths\n",
    "#     audio_file_path = '/kaggle/input/conversation/RES0005.mp3'\n",
    "#     patient_emr_path = '/kaggle/input/conversation/PatientEMR.json'\n",
    "#     soap_ex_path = '/kaggle/input/conversation/soap_example.txt'\n",
    "#     ques_path = '/kaggle/input/conversation/Questionnaire.json'\n",
    "#     qRes_path = '/kaggle/input/conversation/QuestionnaireResponse.json'\n",
    "    \n",
    "#     # Upload only the audio file\n",
    "#     audio_file = upload_to_gemini(audio_file_path)\n",
    "#     print(audio_file)\n",
    "\n",
    "#     with open(soap_ex_path, 'r') as f:\n",
    "#         soap_example = f.read()\n",
    "        \n",
    "#     with open(patient_emr_path, 'r') as f:\n",
    "#         patient_emr = f.read()\n",
    "        \n",
    "#     with open(ques_path, 'r') as f:\n",
    "#         questionnaire = f.read()\n",
    "\n",
    "#     with open(qRes_path, 'r') as f:\n",
    "#         questionnaireRes_example = f.read()\n",
    "\n",
    "#     questionnaire_response = get_questionnaire_response(patient_emr, audio_file, questionnaire, questionnaireRes_example)\n",
    "#     print(questionnaire_response)\n",
    "#     print('-'*100)\n",
    "#     soap_note = generate_soap_note_from_audio(patient_emr, audio_file, soap_example)\n",
    "#     print(soap_note)\n",
    "#     print('-'*100)\n",
    "#     evaluation = evaluate_outputs(patient_emr, audio_file, questionnaire_response, soap_note, questionnaireRes_example, soap_example)\n",
    "#     print(evaluation)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7114367,
     "sourceId": 11400356,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
