{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be2b767-49fe-4d9d-89d3-25cc5545a300",
   "metadata": {},
   "source": [
    "# AI-Powered Clinical Documentation Assistant\n",
    "\n",
    "# Background\n",
    "\n",
    "Healthcare professionals face a significant burden from medical documentation. This project focuses on leveraging generative AI to alleviate this burden by automatically extracting structured information from physician-patient audio conversations and using it to pre-fill administrative forms and generate FHIR resources.\n",
    "\n",
    "Converting form data to FHIR resources ensures seamless integration with existing healthcare systems through a standardized, interoperable format. This structured approach unlocks the data's potential for reusability in various clinical workflows, analytics, and future healthcare applications beyond just form filling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99616c-13a5-49f7-8714-674c4d893cc9",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "**Install library dependencies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16edec1-7f10-4386-a87b-1ff60397b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n",
    "!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\" \"requests==2.32.3\" \"langchain==0.3.23\" \"langgraph==0.3.29\" \"json-repair==0.41.1\" \"google-api-core==2.24.2\" \"langchain-google-genai==2.1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17849f-1c4b-4570-8642-8eedbd36e43d",
   "metadata": {},
   "source": [
    "**Set up your API key**\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d848d2-0ffc-478d-a4ee-fd02e8636e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7f71ec-1170-42a2-85ec-5e03ea497f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_API_KEY=\"AIzaSyDAZjElfeaJqItRsB21v3p4ETShat1PzmI\"\n",
    "\n",
    "# print(dict(os.environ))\n",
    "\n",
    "# os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323ff8b-d9fd-4917-8a37-92f6305d14f1",
   "metadata": {},
   "source": [
    "**Prepare the data store and embeddings**\n",
    "\n",
    "Discover the questionnaire metadata that we will use to create an embedding database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f52747-cebb-40ee-8e1d-a33c52a638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "HAPI_FHIR_BASE_URL = \"https://hapi.fhir.org/baseR4\"\n",
    "HAPI_FHIR_BASE_URL = \"http://localhost:8081/fhir\"\n",
    "QUESTIONNAIRE_ENDPOINT = f\"{HAPI_FHIR_BASE_URL}/Questionnaire\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f72d0b7-5e44-4d8e-b0f9-711b05dc9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8081/fhir/Questionnaire/health-history-questionnaire-2021-06\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def push_sample_questionnaire():\n",
    "    # TODO - read questionnaire json file\n",
    "    with open(\"./quest.json\", \"r\") as file:\n",
    "        raw_quest = json.loads(file.read())\n",
    "    raw_quest_id = raw_quest.get(\"id\")\n",
    "    put_uri = f\"{QUESTIONNAIRE_ENDPOINT}/{raw_quest_id}\"\n",
    "    print(put_uri)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/fhir+json\"\n",
    "    }\n",
    "    response = requests.put(put_uri, json=raw_quest, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "push_sample_questionnaire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa050ee6-6a3c-411c-b352-da10c5a98e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def fetch_questionnaires_from_hapi() -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetches all Questionnaire resources from the HAPI FHIR server.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of Questionnaire resources in JSON format.\n",
    "                     Returns an empty list if there's an error.\n",
    "    \"\"\"\n",
    "    questionnaires = []\n",
    "    try:\n",
    "        # fetch only the last 50 updated records\n",
    "        questionnaire_count = 50\n",
    "        all_params = {\"_count\": questionnaire_count, \"_sort\": \"-_lastUpdated\", \"_elements\":\"description,id,identifier,name,title\"}\n",
    "        response = requests.get(QUESTIONNAIRE_ENDPOINT,params=all_params, headers={\"Accept\": \"application/fhir+json\"})\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        bundle = response.json()\n",
    "\n",
    "        if bundle.get('resourceType') == 'Bundle' and bundle.get('type') == 'searchset':\n",
    "            for entry in bundle.get('entry', []):\n",
    "                if entry.get('resource') and entry['resource'].get('resourceType') == 'Questionnaire':\n",
    "                    questionnaires.append(entry['resource'])\n",
    "        else:\n",
    "            print(f\"Unexpected response format from FHIR server: {bundle.get('resourceType')}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching Questionnaires from HAPI FHIR: {e}\")\n",
    "        return []  # Return empty list in case of error\n",
    "\n",
    "    return questionnaires\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2631970-c89c-4e49-9a98-f1423ca6ac8c",
   "metadata": {},
   "source": [
    "## Creating the embedding database with ChromaDB\n",
    "\n",
    "We create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. \n",
    "\n",
    "The questionnaire metadata are the items that are in the database. They are inserted first, and later retrieved. Queries will be a description of the form to be filled derived from the prompt instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e9279a-aa5f-4821-96d0-ac08fea942d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "from google.genai import types, Client\n",
    "\n",
    "gda_client = Client(api_key=GOOGLE_API_KEY)\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        response = gda_client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=embedding_task,\n",
    "            ),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9532e-3916-4f60-a52c-364bdd0bcbd2",
   "metadata": {},
   "source": [
    "Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `GeminiEmbeddingFunction` and populate the database with the questionnaire metadata from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d84b8cfc-ee27-4017-a56c-65e64f798f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A questionnaire to collect basic health history information.'] ['health-history-questionnaire-2021-06']\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"fhir-questionnaire\"\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "def populate_vector_db():\n",
    "    embed_fn.document_mode = True\n",
    "    quest_docs = fetch_questionnaires_from_hapi()\n",
    "    quest_ids = [x.get(\"id\") for x in quest_docs]\n",
    "    quest_docs = [doc.get(\"description\") for doc in quest_docs]\n",
    "\n",
    "    print(quest_docs, quest_ids)\n",
    "    print(type(quest_docs[0]))\n",
    "    \n",
    "    db.add(documents=quest_docs, ids=quest_ids)\n",
    "\n",
    "populate_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5598e8-acac-43cf-8713-1dae231217e3",
   "metadata": {},
   "source": [
    "Confirm that the data was inserted by looking at the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5000694e-9d36-4cd0-8c73-235a34035a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.count()\n",
    "# You can peek at the data too.\n",
    "# db.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e89f9dc-2396-4e24-96ad-f07c080703ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict, Any, Dict\n",
    "\n",
    "# Define the state of our graph\n",
    "class AgentState(TypedDict):\n",
    "    audio_file_path: Any\n",
    "    instructions: str\n",
    "    transcription: str\n",
    "    quest: Dict[str, Any]\n",
    "    medical_records: str\n",
    "    quest_resp: str\n",
    "    quest_found: bool\n",
    "    quest_resp_valid: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce7795d-b5b6-4298-aaef-52da98512a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_workflow(state: AgentState):\n",
    "    \"\"\" \n",
    "    Start: preserves input prompt, which includes audio file and prompt instructions\n",
    "    \"\"\"\n",
    "    return {\"audio_file_path\": state[\"audio_file_path\"], \"instructions\": state[\"instructions\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556310e4-922c-461d-9e81-d67cc25e2d01",
   "metadata": {},
   "source": [
    "## Retrieval: Finding relevant questionnaires\n",
    "\n",
    "We can then use the prompt to get the questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a46ebc9-0f57-4c98-b88f-e9ac9ddba8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.1210062503814697]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.7042571306228638]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.1676912307739258]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.0279518365859985]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.267957091331482]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.9560441374778748]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.2700376510620117]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.0615557432174683]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.105920672416687]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.737341582775116]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "{'ids': [['health-history-questionnaire-2021-06']], 'embeddings': None, 'documents': [['A questionnaire to collect basic health history information.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.5912556648254395]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "def discover_questionnaire(query):\n",
    "    try:\n",
    "        embed_fn.document_mode = False\n",
    "        result = db.query(query_texts=[query], n_results=1)\n",
    "        # TODO -> how we parse the results here\n",
    "        print(result)\n",
    "        [all_passages] = result[\"documents\"]\n",
    "        return result[\"ids\"][0][0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def fetch_questionnaire(state: AgentState):\n",
    "    query = state.get(\"instructions\")\n",
    "    quest_id = discover_questionnaire(query)\n",
    "    print(\"questionnaire_id\", quest_id)\n",
    "    if quest_id is None:\n",
    "        return {quest_found: False}\n",
    "    response = requests.get(f\"{QUESTIONNAIRE_ENDPOINT}/{quest_id}\", headers={\"Accept\": \"application/fhir+json\"})\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    quest = response.json()\n",
    "    return {\"quest_found\": True, \"quest\": quest}\n",
    "\n",
    "\n",
    "form_instructions = [\n",
    "    \"Enter your full name in the registration form.\",\n",
    "    \"Provide your medical history in the health screening form.\",\n",
    "    \"Fill in your contact number in the application form.\",\n",
    "    \"Sign the patient consent form before the procedure.\",\n",
    "    \"Rate our service in the feedback form.\",\n",
    "    \"List any allergies in the wellness intake form.\",\n",
    "    \"Add your shipping address in the order form.\",\n",
    "    \"Update your vaccination dates in the immunization record form.\",\n",
    "    \"Select your preferred contact method in the survey form.\",\n",
    "    \"Submit your emergency contact details in the health registration form.\"\n",
    "    \"Fill out a health history questionnaire\",\n",
    "    \"Fill out a medical history form\"\n",
    "]\n",
    "\n",
    "for instruction in form_instructions:\n",
    "    discover_questionnaire(instruction)\n",
    "\n",
    "\n",
    "# response = discover_questionnaire(\"A questionnaire to collect basic health history information.\")\n",
    "# # print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c6b6af-2f2a-4067-beb0-3477bce6ba25",
   "metadata": {},
   "source": [
    "# Now that we have the questionnaire and the transcripted audio files, we can move on to generate the questionnaireResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7030480-db47-4d1c-8c63-fd7c3ee69096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_repair\n",
    "google_model_id = \"gemini-2.0-flash\"\n",
    "\n",
    "def generate_questresp(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Extract relevant information,\n",
    "    and return a FHIR QuestionnaireResponse resource as a dict.\n",
    "    \"\"\"\n",
    "    transcribed = state.get(\"transcription\")\n",
    "    questionnaire = state.get(\"quest\")\n",
    "    # 3. Prepare the LLM prompt\n",
    "    prompt = create_prompt_for_questionnaire_response(\n",
    "        transcribed, questionnaire\n",
    "    )\n",
    "\n",
    "    response = gda_client.models.generate_content(\n",
    "        model=google_model_id, contents=[prompt, transcribed], config={\n",
    "            'response_mime_type': 'application/json'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    qr_string = response.text.strip()\n",
    "    qr = json_repair.loads(qr_string)\n",
    "    # try:\n",
    "    #     questionnaire_response = json.loads(llm_output)\n",
    "    # except Exception as e:\n",
    "    #     raise ValueError(f\"Invalid JSON from LLM: {e}\")\n",
    "\n",
    "    # # 6. Validate the JSON against FHIR schema (optional but recommended)\n",
    "    # #    This step ensures the object meets the QuestionnaireResponse structure\n",
    "    # if not validate_fhir_questionnaire_response(questionnaire_response):\n",
    "    #     raise ValueError(\"Generated QuestionnaireResponse is not valid FHIR.\")\n",
    "\n",
    "    # # 7. Return or store the final resource\n",
    "    return {\"quest_resp\": qr}\n",
    "\n",
    "\n",
    "def create_prompt_for_questionnaire_response(\n",
    "    cleaned_text: str, questionnaire_template: dict\n",
    ") -> str:\n",
    "    # Construct a system/user prompt with instructions,\n",
    "    # referencing relevant sections of the conversation\n",
    "    prompt = f\"\"\"\n",
    "    You are a medical documentation assistant.\n",
    "    Below is a transcribed patient-physician conversation:\n",
    "    ---\n",
    "    {cleaned_text}\n",
    "    ---\n",
    "\n",
    "    You have a FHIR Questionnaire defined as follows:\n",
    "    {json.dumps(questionnaire_template, indent=2)}\n",
    "\n",
    "    Extract the relevant data from the conversation to populate a FHIR QuestionnaireResponse\n",
    "    based on the provided Questionnaire. Return ONLY valid JSON representing this \n",
    "    QuestionnaireResponse with fields \"resourceType\": \"QuestionnaireResponse\", \n",
    "    \"questionnaire\": \"<Questionnaire-identifier>\",\n",
    "    \"status\", \"subject\", \"authored\", \"item\", etc.\n",
    "\n",
    "    If a field is unknown, leave it blank or null. \n",
    "    Do not add additional commentary.\n",
    "\n",
    "    Use this JSON schema:\n",
    "\n",
    "    QuestionnaireResponse = <generated questionnaireResponse>\n",
    "    return: QuestionnaireResponse\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af628e5f-1b4e-4f11-a4a6-006f2a62ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_qr(state: AgentState):\n",
    "    qr = state.get(\"quest_resp\")\n",
    "    # use a publicly available fhir instance.\n",
    "    url = f\"{QUESTIONNAIRE_ENDPOINT}/$validate\"\n",
    "    headers = {\"Content-Type\": \"application/fhir+json\"}\n",
    "\n",
    "    response = requests.post(url, json=qr, headers=headers)\n",
    "    if response.ok:\n",
    "        return {\"quest_resp_valid\": True}\n",
    "    else:\n",
    "        return {\"quest_resp_valid\": False}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b21fbad-fae6-4732-acee-9c0d8481215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_questionnaire_response(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Saves the validated QuestionnaireResponse to the HAPI FHIR server.\n",
    "\n",
    "    Args:\n",
    "        questionnaire_response (Dict): The validated FHIR QuestionnaireResponse in JSON format.\n",
    "\n",
    "    Returns:\n",
    "        str: A success message or an error message if saving fails.\n",
    "    \"\"\"\n",
    "    quest_resp = state.get(\"quest_resp\")\n",
    "    print(\"\\n\\n\\n\\n\",quest_resp, type(quest_resp))\n",
    "    questionnaire_response_endpoint = f\"{HAPI_FHIR_BASE_URL}/QuestionnaireResponse\"\n",
    "    headers = {\"Accept\": \"application/fhir+json\", \"Content-Type\": \"application/fhir+json\"}\n",
    "\n",
    "    response = requests.post(questionnaire_response_endpoint, headers=headers, json=quest_resp)\n",
    "    response.raise_for_status() # Raise exception for HTTP errors\n",
    "\n",
    "    if response.status_code in range(200, 300):\n",
    "        created_resource = response.json()\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8a1adf-245d-4ab1-a197-c144bb5d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transcription Function ---\n",
    "# TODO - why do we need to this.\n",
    "def diarize_audio(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transcribes the given audio file using the Gemini model, aiming for a\n",
    "    conversation-style output with speaker labels.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized Gemini GenerativeModel instance.\n",
    "        audio_file_path: Path to the audio file (e.g., .wav, .mp3, .flac).\n",
    "    \"\"\"\n",
    "    # TODO - check that audio format is supported.\n",
    "    uploaded_file = state[\"audio_file_path\"]\n",
    "\n",
    "    \n",
    "    # 2. Construct the Prompt - Key Considerations for Conversation Style:\n",
    "    #    - Explicitly ask for transcription.\n",
    "    #    - Request speaker diarization (identifying and labeling speakers).\n",
    "    #    - Suggest common labels (like 'Doctor:', 'Patient:', or 'Speaker 1:', 'Speaker 2:').\n",
    "    #    - Ask for natural punctuation and formatting.\n",
    "    #    - Specify how to handle non-speech sounds (ignore, note in brackets, etc.).\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Diarize and transcribe this health-related interview, maintaining chronological order with timestamps if possible. Add labels for speaker (like 'Doctor:', 'Patient:', or 'Speaker 1:', 'Speaker 2:') at the beginning of each turn.\n",
    "    Accurately capture medical terms, mark unclear words as “[INAUDIBLE],” avoid adding extra commentary or guesses, and keep overlapping speech on separate lines. \n",
    "    Return only the final transcript.\n",
    "    \"\"\"\n",
    "\n",
    "    response = gda_client.models.generate_content(\n",
    "        model=google_model_id,\n",
    "        contents = [prompt, uploaded_file]\n",
    "    )\n",
    "\n",
    "    transcription = response.text.strip()\n",
    "    return {\"transcription\": transcription}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cb0d9c-0d11-4c0c-b0bf-289f47d089d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_workflow(state: AgentState):\n",
    "    # TODO - \n",
    "    print(\"Workflow end\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0977e35d-093d-41d8-a84a-11497c240bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI # Correct import path\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "# from langgraph.pregel import PregelProcess # TODO???\n",
    "\n",
    "model_id = \"gemini-2.0-flash\"\n",
    "model = ChatGoogleGenerativeAI(model=model_id, google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Defined the graph\n",
    "wk_graph = StateGraph(AgentState)\n",
    "\n",
    "# Nodes\n",
    "wk_graph.add_node(\"discover_and_fetch_questionnaire\", fetch_questionnaire)\n",
    "wk_graph.add_node(\"transcribe_audio\", diarize_audio)\n",
    "wk_graph.add_node(\"generate_questionnaire_response\", generate_questresp)\n",
    "wk_graph.add_node(\"repair_and_validate_questionnaire_response\", validate_qr)\n",
    "wk_graph.add_node(\"save_response\", save_questionnaire_response)\n",
    "wk_graph.add_node(\"terminate_workflow\", terminate_workflow)\n",
    "\n",
    "# Edges\n",
    "wk_graph.add_edge(START, \"discover_and_fetch_questionnaire\")\n",
    "wk_graph.add_conditional_edges(\"discover_and_fetch_questionnaire\", lambda state: \"transcribe_audio\" if state[\"quest_found\"] else \"terminate_workflow\")\n",
    "wk_graph.add_edge(\"transcribe_audio\", \"generate_questionnaire_response\")\n",
    "wk_graph.add_edge(\"generate_questionnaire_response\", \"repair_and_validate_questionnaire_response\")\n",
    "wk_graph.add_edge(\"repair_and_validate_questionnaire_response\", \"save_response\")\n",
    "wk_graph.add_edge(\"save_response\", \"terminate_workflow\")\n",
    "wk_graph.add_edge(\"discover_and_fetch_questionnaire\", \"terminate_workflow\")\n",
    "wk_graph.add_edge(\"terminate_workflow\", END)\n",
    "\n",
    "\n",
    "\n",
    "graph = wk_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8fa31d2-eeef-4862-b25b-2450610b75f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1da3816a-4851-4231-b456-91d167fb6426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uploaded_file_uri' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# local_input_file_url = \"./Data/Audio Recordings/CAR0002.mp3\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# uploaded_file_uri = gda_client.files.upload(file=local_input_file_url)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33maudio_file_path\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43muploaded_file_uri\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mProcess audio and fill out a medical history report\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m      5\u001b[39m result = graph.invoke(inputs)\n",
      "\u001b[31mNameError\u001b[39m: name 'uploaded_file_uri' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# local_input_file_url = \"./Data/Audio Recordings/CAR0002.mp3\"\n",
    "# uploaded_file_uri = gda_client.files.upload(file=local_input_file_url)\n",
    "\n",
    "inputs = {\"audio_file_path\": uploaded_file_uri, \"instructions\": \"Process audio and fill out a medical history report\"}\n",
    "result = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67caa6e-e2eb-4fbb-80d4-c649ae61d2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
